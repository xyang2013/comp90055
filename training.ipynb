{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset computational graph\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38076, 10, 53)\n",
      "(38076, 3)\n",
      "(2212, 10, 53)\n",
      "(2212, 3)\n",
      "(2212, 10, 53)\n",
      "(2212, 3)\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data.bin'\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    X_train_upsampled = np.load(f).astype(np.float32)\n",
    "    y_train_upsampled_onehot = np.load(f).astype(np.float32)\n",
    "    X_valid = np.load(f).astype(np.float32)\n",
    "    y_valid_onehot = np.load(f).astype(np.float32)\n",
    "    X_test = np.load(f).astype(np.float32)\n",
    "    y_test_onehot = np.load(f).astype(np.float32)\n",
    "    \n",
    "print(X_train_upsampled.shape)\n",
    "print(y_train_upsampled_onehot.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid_onehot.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test_onehot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data iteration parameters\n",
    "\n",
    "buffer_size = 500 # buffer size for data shuffling\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training dataset\n",
    "\n",
    "dx_train = tf.data.Dataset.from_tensor_slices(X_train_upsampled)\n",
    "dy_train = tf.data.Dataset.from_tensor_slices(y_train_upsampled_onehot)\n",
    "train_dataset = tf.data.Dataset.zip((dx_train, dy_train)).shuffle(buffer_size).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define validation set\n",
    "\n",
    "dx_valid = tf.data.Dataset.from_tensor_slices(X_valid)\n",
    "dy_valid = tf.data.Dataset.from_tensor_slices(y_valid_onehot)\n",
    "valid_dataset = tf.data.Dataset.zip((dx_valid, dy_valid)).shuffle(buffer_size).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create general iterator\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make datasets that we can initialize separately, but using the same structure via the common iterator\n",
    "\n",
    "training_init_op = iterator.make_initializer(train_dataset)\n",
    "validation_init_op = iterator.make_initializer(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network parameters and structure\n",
    "\n",
    "input_dim = 53\n",
    "output_dim = 3\n",
    "num_steps = 10\n",
    "state_size = 100\n",
    "num_layers = 3\n",
    "learning_rate = 1e-4\n",
    "global_dropout = .8\n",
    "\n",
    "prob = tf.placeholder_with_default(1.0, shape=())\n",
    "\n",
    "def rnn_cell_with_dropout():\n",
    "        cell = tf.nn.rnn_cell.BasicRNNCell(num_units=state_size)\n",
    "        cell = tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=prob)\n",
    "        return cell\n",
    "\n",
    "def nn_model(in_data):  \n",
    "\n",
    "    cells = [rnn_cell_with_dropout() for _ in range(num_layers)]\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "    cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=prob)\n",
    "    \n",
    "    init_state = cell.zero_state(batch_size, tf.float32)\n",
    "    rnn_outputs, _ = tf.nn.dynamic_rnn(cell, in_data, initial_state=init_state)\n",
    "\n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, output_dim])\n",
    "        b = tf.get_variable('b', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    # reshape rnn_outputs and y so we can get the logits in a single matmul\n",
    "    rnn_outputs = rnn_outputs[:, num_steps-1, :] # keep only the last sequence\n",
    "    rnn_outputs = tf.reshape(rnn_outputs, [-1, state_size])\n",
    "\n",
    "    return tf.matmul(rnn_outputs, W) + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete computational graph\n",
    "\n",
    "# forward\n",
    "next_element = iterator.get_next()\n",
    "logits = nn_model(next_element[0])\n",
    "loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(labels=next_element[1], logits=logits))\n",
    "\n",
    "# backward\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# calculate accuracy\n",
    "label = tf.argmax(next_element[1], 1)\n",
    "prediction = tf.argmax(logits, 1)\n",
    "equality = tf.equal(prediction, label)\n",
    "accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 33.901, training accuracy: 45.28%\n",
      "Epoch: 0, loss: 28.786, validation accuracy: 57.02%\n",
      "[[  89  126   24]\n",
      " [ 373 1052  313]\n",
      " [  28   85  118]]\n",
      "Epoch: 1, loss: 32.332, training accuracy: 48.96%\n",
      "Epoch: 1, loss: 28.962, validation accuracy: 58.51%\n",
      "[[  88  119   31]\n",
      " [ 345 1085  307]\n",
      " [  28   86  119]]\n",
      "Epoch: 2, loss: 31.968, training accuracy: 49.80%\n",
      "Epoch: 2, loss: 27.943, validation accuracy: 60.19%\n",
      "[[  94  124   20]\n",
      " [ 319 1130  288]\n",
      " [  30   98  105]]\n",
      "Epoch: 3, loss: 31.777, training accuracy: 50.27%\n",
      "Epoch: 3, loss: 26.961, validation accuracy: 61.32%\n",
      "[[  86  134   19]\n",
      " [ 313 1174  249]\n",
      " [  22  117   94]]\n",
      "Epoch: 4, loss: 31.645, training accuracy: 50.71%\n",
      "Epoch: 4, loss: 29.722, validation accuracy: 56.70%\n",
      "[[ 104  105   30]\n",
      " [ 381 1031  324]\n",
      " [  27   89  117]]\n",
      "Epoch: 5, loss: 31.560, training accuracy: 50.97%\n",
      "Epoch: 5, loss: 29.604, validation accuracy: 57.52%\n",
      "[[ 100  103   35]\n",
      " [ 350 1049  338]\n",
      " [  29   83  121]]\n",
      "Epoch: 6, loss: 31.320, training accuracy: 51.73%\n",
      "Epoch: 6, loss: 28.703, validation accuracy: 60.28%\n",
      "[[  98  113   28]\n",
      " [ 278 1107  352]\n",
      " [  24   82  126]]\n",
      "Epoch: 7, loss: 31.326, training accuracy: 51.85%\n",
      "Epoch: 7, loss: 28.629, validation accuracy: 58.70%\n",
      "[[ 102  112   24]\n",
      " [ 352 1082  305]\n",
      " [  31   88  112]]\n",
      "Epoch: 8, loss: 31.079, training accuracy: 52.73%\n",
      "Epoch: 8, loss: 27.700, validation accuracy: 60.78%\n",
      "[[  99  115   24]\n",
      " [ 328 1143  267]\n",
      " [  28  104  100]]\n",
      "Epoch: 9, loss: 30.847, training accuracy: 52.91%\n",
      "Epoch: 9, loss: 28.598, validation accuracy: 58.65%\n",
      "[[ 109   99   31]\n",
      " [ 392 1087  257]\n",
      " [  36   98   99]]\n",
      "Epoch: 10, loss: 30.752, training accuracy: 53.29%\n",
      "Epoch: 10, loss: 29.871, validation accuracy: 51.54%\n",
      "[[100  89  50]\n",
      " [343 895 499]\n",
      " [ 26  63 143]]\n",
      "Epoch: 11, loss: 30.587, training accuracy: 53.56%\n",
      "Epoch: 11, loss: 28.024, validation accuracy: 59.24%\n",
      "[[ 106  103   29]\n",
      " [ 362 1105  271]\n",
      " [  36   99   97]]\n",
      "Epoch: 12, loss: 30.404, training accuracy: 54.17%\n",
      "Epoch: 12, loss: 28.861, validation accuracy: 57.11%\n",
      "[[ 119   94   26]\n",
      " [ 465 1055  217]\n",
      " [  38  107   87]]\n",
      "Epoch: 13, loss: 30.338, training accuracy: 54.24%\n",
      "Epoch: 13, loss: 27.313, validation accuracy: 62.27%\n",
      "[[  78  136   25]\n",
      " [ 286 1203  247]\n",
      " [  21  118   94]]\n",
      "Epoch: 14, loss: 30.185, training accuracy: 54.50%\n",
      "Epoch: 14, loss: 29.722, validation accuracy: 55.03%\n",
      "[[100  88  51]\n",
      " [390 998 348]\n",
      " [ 33  83 117]]\n",
      "Epoch: 15, loss: 29.860, training accuracy: 55.32%\n",
      "Epoch: 15, loss: 29.420, validation accuracy: 54.85%\n",
      "[[104  91  44]\n",
      " [352 995 390]\n",
      " [ 38  82 112]]\n",
      "Epoch: 16, loss: 29.656, training accuracy: 56.18%\n",
      "Epoch: 16, loss: 29.141, validation accuracy: 54.48%\n",
      "[[104  94  41]\n",
      " [431 996 309]\n",
      " [ 38  92 103]]\n",
      "Epoch: 17, loss: 29.472, training accuracy: 56.31%\n",
      "Epoch: 17, loss: 29.026, validation accuracy: 55.21%\n",
      "[[  98   88   52]\n",
      " [ 380 1017  340]\n",
      " [  35   94  104]]\n",
      "Epoch: 18, loss: 29.345, training accuracy: 56.88%\n",
      "Epoch: 18, loss: 28.941, validation accuracy: 56.39%\n",
      "[[ 108   96   34]\n",
      " [ 395 1037  305]\n",
      " [  40   93  100]]\n",
      "Epoch: 19, loss: 29.241, training accuracy: 56.75%\n",
      "Epoch: 19, loss: 31.654, validation accuracy: 47.87%\n",
      "[[102  78  59]\n",
      " [440 825 474]\n",
      " [ 36  64 130]]\n",
      "Epoch: 20, loss: 29.167, training accuracy: 56.83%\n",
      "Epoch: 20, loss: 29.244, validation accuracy: 54.66%\n",
      "[[ 100   97   41]\n",
      " [ 405 1008  324]\n",
      " [  37   97   99]]\n",
      "Epoch: 21, loss: 29.023, training accuracy: 57.49%\n",
      "Epoch: 21, loss: 30.209, validation accuracy: 52.72%\n",
      "[[113  82  44]\n",
      " [466 958 312]\n",
      " [ 46  94  93]]\n",
      "Epoch: 22, loss: 28.922, training accuracy: 57.09%\n",
      "Epoch: 22, loss: 29.210, validation accuracy: 55.25%\n",
      "[[  94   97   47]\n",
      " [ 370 1030  338]\n",
      " [  38   98   96]]\n",
      "Epoch: 23, loss: 28.836, training accuracy: 57.46%\n",
      "Epoch: 23, loss: 30.129, validation accuracy: 52.45%\n",
      "[[ 99  99  41]\n",
      " [442 965 329]\n",
      " [ 52  87  94]]\n",
      "Epoch: 24, loss: 28.725, training accuracy: 57.85%\n",
      "Epoch: 24, loss: 30.135, validation accuracy: 53.40%\n",
      "[[101  93  45]\n",
      " [388 972 377]\n",
      " [ 40  86 106]]\n",
      "Epoch: 25, loss: 28.587, training accuracy: 58.23%\n",
      "Epoch: 25, loss: 29.915, validation accuracy: 53.53%\n",
      "[[ 97  97  45]\n",
      " [376 973 387]\n",
      " [ 41  80 112]]\n",
      "Epoch: 26, loss: 28.500, training accuracy: 58.18%\n",
      "Epoch: 26, loss: 30.652, validation accuracy: 52.22%\n",
      "[[106  86  47]\n",
      " [453 954 329]\n",
      " [ 55  85  93]]\n",
      "Epoch: 27, loss: 28.428, training accuracy: 58.36%\n",
      "Epoch: 27, loss: 29.920, validation accuracy: 54.66%\n",
      "[[  97   97   45]\n",
      " [ 373 1001  362]\n",
      " [  39   85  109]]\n",
      "Epoch: 28, loss: 28.337, training accuracy: 58.98%\n",
      "Epoch: 28, loss: 30.963, validation accuracy: 50.32%\n",
      "[[112  77  49]\n",
      " [444 895 398]\n",
      " [ 45  84 104]]\n",
      "Epoch: 29, loss: 28.384, training accuracy: 58.64%\n",
      "Epoch: 29, loss: 29.039, validation accuracy: 54.62%\n",
      "[[  85  108   46]\n",
      " [ 312 1008  416]\n",
      " [  31   89  113]]\n",
      "Epoch: 30, loss: 28.322, training accuracy: 58.59%\n",
      "Epoch: 30, loss: 29.566, validation accuracy: 52.13%\n",
      "[[ 90 103  46]\n",
      " [365 950 421]\n",
      " [ 40  82 111]]\n",
      "Epoch: 31, loss: 28.298, training accuracy: 58.54%\n",
      "Epoch: 31, loss: 29.770, validation accuracy: 53.99%\n",
      "[[108  83  47]\n",
      " [412 983 342]\n",
      " [ 49  83 101]]\n",
      "Epoch: 32, loss: 28.138, training accuracy: 59.13%\n",
      "Epoch: 32, loss: 28.767, validation accuracy: 56.66%\n",
      "[[  95  101   43]\n",
      " [ 370 1057  309]\n",
      " [  45   89   99]]\n",
      "Epoch: 33, loss: 28.294, training accuracy: 58.93%\n",
      "Epoch: 33, loss: 30.260, validation accuracy: 51.00%\n",
      "[[108  87  44]\n",
      " [405 914 419]\n",
      " [ 41  86 104]]\n",
      "Epoch: 34, loss: 28.122, training accuracy: 59.10%\n",
      "Epoch: 34, loss: 29.653, validation accuracy: 52.36%\n",
      "[[109  86  43]\n",
      " [434 949 355]\n",
      " [ 46  88  98]]\n",
      "Epoch: 35, loss: 28.122, training accuracy: 59.19%\n",
      "Epoch: 35, loss: 30.361, validation accuracy: 51.95%\n",
      "[[107  77  55]\n",
      " [425 948 363]\n",
      " [ 46  95  92]]\n",
      "Epoch: 36, loss: 28.178, training accuracy: 59.25%\n",
      "Epoch: 36, loss: 29.754, validation accuracy: 51.99%\n",
      "[[ 90  99  50]\n",
      " [384 952 402]\n",
      " [ 39  86 106]]\n",
      "Epoch: 37, loss: 28.130, training accuracy: 59.08%\n",
      "Epoch: 37, loss: 29.070, validation accuracy: 55.71%\n",
      "[[  92  100   47]\n",
      " [ 336 1037  364]\n",
      " [  42   89  101]]\n",
      "Epoch: 38, loss: 27.984, training accuracy: 59.33%\n",
      "Epoch: 38, loss: 29.368, validation accuracy: 55.25%\n",
      "[[ 100   87   51]\n",
      " [ 368 1012  357]\n",
      " [  37   88  108]]\n",
      "Epoch: 39, loss: 28.072, training accuracy: 59.14%\n",
      "Epoch: 39, loss: 29.584, validation accuracy: 53.99%\n",
      "[[ 92  90  56]\n",
      " [374 999 364]\n",
      " [ 41  91 101]]\n",
      "Epoch: 40, loss: 27.896, training accuracy: 59.61%\n",
      "Epoch: 40, loss: 29.424, validation accuracy: 53.44%\n",
      "[[ 97  95  47]\n",
      " [414 995 327]\n",
      " [ 51  94  88]]\n",
      "Epoch: 41, loss: 28.050, training accuracy: 59.25%\n",
      "Epoch: 41, loss: 30.450, validation accuracy: 51.54%\n",
      "[[ 87  93  58]\n",
      " [433 956 349]\n",
      " [ 49  88  95]]\n",
      "Epoch: 42, loss: 27.945, training accuracy: 59.45%\n",
      "Epoch: 42, loss: 29.387, validation accuracy: 54.39%\n",
      "[[ 109   84   45]\n",
      " [ 417 1002  319]\n",
      " [  53   89   90]]\n",
      "Epoch: 43, loss: 27.996, training accuracy: 59.73%\n",
      "Epoch: 43, loss: 30.337, validation accuracy: 51.27%\n",
      "[[ 94  89  55]\n",
      " [406 934 397]\n",
      " [ 49  80 104]]\n",
      "Epoch: 44, loss: 27.927, training accuracy: 59.31%\n",
      "Epoch: 44, loss: 29.828, validation accuracy: 52.45%\n",
      "[[ 85  99  53]\n",
      " [410 975 353]\n",
      " [ 51  84  98]]\n",
      "Epoch: 45, loss: 27.854, training accuracy: 59.64%\n",
      "Epoch: 45, loss: 29.145, validation accuracy: 54.71%\n",
      "[[ 101   89   49]\n",
      " [ 408 1017  313]\n",
      " [  53   88   90]]\n",
      "Epoch: 46, loss: 27.996, training accuracy: 59.23%\n",
      "Epoch: 46, loss: 29.715, validation accuracy: 52.13%\n",
      "[[107  93  39]\n",
      " [445 953 338]\n",
      " [ 46  96  91]]\n",
      "Epoch: 47, loss: 27.903, training accuracy: 59.42%\n",
      "Epoch: 47, loss: 29.898, validation accuracy: 52.36%\n",
      "[[110  93  36]\n",
      " [423 956 357]\n",
      " [ 51  92  90]]\n",
      "Epoch: 48, loss: 27.952, training accuracy: 59.42%\n",
      "Epoch: 48, loss: 30.050, validation accuracy: 51.59%\n",
      "[[ 93  91  54]\n",
      " [367 944 427]\n",
      " [ 52  78 102]]\n",
      "Epoch: 49, loss: 27.846, training accuracy: 59.59%\n",
      "Epoch: 49, loss: 29.422, validation accuracy: 52.90%\n",
      "[[ 97  99  42]\n",
      " [424 963 350]\n",
      " [ 49  76 108]]\n",
      "Epoch: 50, loss: 27.834, training accuracy: 59.92%\n",
      "Epoch: 50, loss: 29.876, validation accuracy: 51.99%\n",
      "[[108  87  44]\n",
      " [439 940 357]\n",
      " [ 53  80 100]]\n",
      "Epoch: 51, loss: 27.928, training accuracy: 59.41%\n",
      "Epoch: 51, loss: 29.845, validation accuracy: 51.95%\n",
      "[[ 93 101  45]\n",
      " [424 951 362]\n",
      " [ 48  81 103]]\n",
      "Epoch: 52, loss: 27.835, training accuracy: 59.94%\n",
      "Epoch: 52, loss: 30.172, validation accuracy: 51.63%\n",
      "[[ 99  97  41]\n",
      " [482 945 312]\n",
      " [ 55  81  96]]\n",
      "Epoch: 53, loss: 27.840, training accuracy: 59.51%\n",
      "Epoch: 53, loss: 29.891, validation accuracy: 52.72%\n",
      "[[ 96 100  42]\n",
      " [439 971 328]\n",
      " [ 50  85  97]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54, loss: 27.906, training accuracy: 59.42%\n",
      "Epoch: 54, loss: 28.709, validation accuracy: 57.38%\n",
      "[[  86  107   46]\n",
      " [ 390 1082  264]\n",
      " [  43   91   99]]\n",
      "Epoch: 55, loss: 27.892, training accuracy: 59.48%\n",
      "Epoch: 55, loss: 29.892, validation accuracy: 53.17%\n",
      "[[ 95 100  42]\n",
      " [434 981 324]\n",
      " [ 51  83  98]]\n",
      "Epoch: 56, loss: 27.953, training accuracy: 59.63%\n",
      "Epoch: 56, loss: 29.443, validation accuracy: 53.80%\n",
      "[[ 98  95  45]\n",
      " [427 995 315]\n",
      " [ 48  90  95]]\n",
      "Epoch: 57, loss: 28.019, training accuracy: 59.22%\n",
      "Epoch: 57, loss: 29.376, validation accuracy: 53.17%\n",
      "[[ 95 104  39]\n",
      " [442 981 314]\n",
      " [ 48  87  98]]\n",
      "Epoch: 58, loss: 27.902, training accuracy: 59.54%\n",
      "Epoch: 58, loss: 31.212, validation accuracy: 50.05%\n",
      "[[114  78  46]\n",
      " [509 891 337]\n",
      " [ 55  78 100]]\n",
      "Epoch: 59, loss: 28.018, training accuracy: 59.59%\n",
      "Epoch: 59, loss: 30.158, validation accuracy: 51.36%\n",
      "[[ 96  97  45]\n",
      " [424 937 377]\n",
      " [ 52  79 101]]\n",
      "Epoch: 60, loss: 28.125, training accuracy: 59.12%\n",
      "Epoch: 60, loss: 30.254, validation accuracy: 51.31%\n",
      "[[109  83  46]\n",
      " [473 927 337]\n",
      " [ 51  85  97]]\n",
      "Epoch: 61, loss: 28.094, training accuracy: 59.34%\n",
      "Epoch: 61, loss: 28.528, validation accuracy: 56.34%\n",
      "[[  94  102   42]\n",
      " [ 355 1059  324]\n",
      " [  46   95   91]]\n",
      "Epoch: 62, loss: 27.948, training accuracy: 59.77%\n",
      "Epoch: 62, loss: 29.728, validation accuracy: 52.76%\n",
      "[[ 97  94  47]\n",
      " [403 960 374]\n",
      " [ 34  91 108]]\n",
      "Epoch: 63, loss: 28.035, training accuracy: 59.36%\n",
      "Epoch: 63, loss: 30.529, validation accuracy: 50.27%\n",
      "[[104  90  45]\n",
      " [448 892 396]\n",
      " [ 54  65 114]]\n",
      "Epoch: 64, loss: 28.057, training accuracy: 59.26%\n",
      "Epoch: 64, loss: 28.324, validation accuracy: 56.66%\n",
      "[[  88  108   43]\n",
      " [ 326 1061  349]\n",
      " [  42   89  102]]\n",
      "Epoch: 65, loss: 28.003, training accuracy: 59.52%\n",
      "Epoch: 65, loss: 30.957, validation accuracy: 49.64%\n",
      "[[103  88  48]\n",
      " [471 881 384]\n",
      " [ 50  71 112]]\n",
      "Epoch: 66, loss: 28.186, training accuracy: 59.07%\n",
      "Epoch: 66, loss: 29.013, validation accuracy: 54.44%\n",
      "[[  89  102   46]\n",
      " [ 394 1008  336]\n",
      " [  47   81  105]]\n",
      "Epoch: 67, loss: 28.252, training accuracy: 58.56%\n",
      "Epoch: 67, loss: 29.809, validation accuracy: 53.67%\n",
      "[[110  87  42]\n",
      " [452 988 298]\n",
      " [ 50  94  87]]\n",
      "Epoch: 68, loss: 28.377, training accuracy: 58.55%\n",
      "Epoch: 68, loss: 30.206, validation accuracy: 52.04%\n",
      "[[106  74  59]\n",
      " [424 945 369]\n",
      " [ 54  79  98]]\n",
      "Epoch: 69, loss: 28.143, training accuracy: 59.28%\n",
      "Epoch: 69, loss: 29.107, validation accuracy: 53.80%\n",
      "[[ 91 102  44]\n",
      " [366 994 378]\n",
      " [ 45  85 103]]\n",
      "Epoch: 70, loss: 28.468, training accuracy: 58.59%\n",
      "Epoch: 70, loss: 29.624, validation accuracy: 53.67%\n",
      "[[ 96  95  48]\n",
      " [369 985 382]\n",
      " [ 43  86 104]]\n",
      "Epoch: 71, loss: 28.425, training accuracy: 58.39%\n",
      "Epoch: 71, loss: 29.240, validation accuracy: 56.11%\n",
      "[[  86  109   43]\n",
      " [ 352 1059  327]\n",
      " [  43   95   94]]\n",
      "Epoch: 72, loss: 28.407, training accuracy: 58.62%\n",
      "Epoch: 72, loss: 29.259, validation accuracy: 54.17%\n",
      "[[  83  104   51]\n",
      " [ 373 1020  344]\n",
      " [  47   93   93]]\n",
      "Epoch: 73, loss: 28.471, training accuracy: 58.34%\n",
      "Epoch: 73, loss: 30.286, validation accuracy: 50.45%\n",
      "[[ 86 100  53]\n",
      " [393 924 419]\n",
      " [ 45  84 104]]\n",
      "Epoch: 74, loss: 28.382, training accuracy: 58.70%\n",
      "Epoch: 74, loss: 29.435, validation accuracy: 54.21%\n",
      "[[104  82  53]\n",
      " [419 993 324]\n",
      " [ 43  90 100]]\n",
      "Epoch: 75, loss: 28.432, training accuracy: 58.69%\n",
      "Epoch: 75, loss: 29.676, validation accuracy: 53.58%\n",
      "[[ 86 110  43]\n",
      " [389 992 355]\n",
      " [ 44  84 105]]\n",
      "Epoch: 76, loss: 28.473, training accuracy: 58.28%\n",
      "Epoch: 76, loss: 30.975, validation accuracy: 51.09%\n",
      "[[105  82  52]\n",
      " [434 912 390]\n",
      " [ 48  74 111]]\n",
      "Epoch: 77, loss: 28.574, training accuracy: 58.21%\n",
      "Epoch: 77, loss: 31.708, validation accuracy: 49.32%\n",
      "[[106  78  55]\n",
      " [435 862 439]\n",
      " [ 44  68 121]]\n",
      "Epoch: 78, loss: 28.584, training accuracy: 58.41%\n",
      "Epoch: 78, loss: 29.587, validation accuracy: 56.20%\n",
      "[[  93  103   42]\n",
      " [ 350 1045  343]\n",
      " [  44   85  103]]\n",
      "Epoch: 79, loss: 28.767, training accuracy: 58.12%\n",
      "Epoch: 79, loss: 30.204, validation accuracy: 53.67%\n",
      "[[104  86  48]\n",
      " [446 982 309]\n",
      " [ 51  83  99]]\n",
      "Epoch: 80, loss: 28.685, training accuracy: 58.10%\n",
      "Epoch: 80, loss: 29.137, validation accuracy: 56.48%\n",
      "[[  86   99   52]\n",
      " [ 326 1056  356]\n",
      " [  38   90  105]]\n",
      "Epoch: 81, loss: 28.746, training accuracy: 57.96%\n",
      "Epoch: 81, loss: 30.240, validation accuracy: 50.68%\n",
      "[[ 98  86  54]\n",
      " [428 911 398]\n",
      " [ 48  75 110]]\n",
      "Epoch: 82, loss: 28.786, training accuracy: 58.02%\n",
      "Epoch: 82, loss: 29.355, validation accuracy: 54.12%\n",
      "[[ 90 100  48]\n",
      " [359 994 385]\n",
      " [ 44  77 111]]\n",
      "Epoch: 83, loss: 28.910, training accuracy: 57.74%\n",
      "Epoch: 83, loss: 29.170, validation accuracy: 55.03%\n",
      "[[  90   98   51]\n",
      " [ 385 1023  329]\n",
      " [  41   89  102]]\n",
      "Epoch: 84, loss: 28.963, training accuracy: 57.40%\n",
      "Epoch: 84, loss: 28.990, validation accuracy: 53.71%\n",
      "[[ 84 108  47]\n",
      " [376 997 365]\n",
      " [ 42  84 105]]\n",
      "Epoch: 85, loss: 28.971, training accuracy: 57.35%\n",
      "Epoch: 85, loss: 29.785, validation accuracy: 53.53%\n",
      "[[ 92  95  52]\n",
      " [422 997 318]\n",
      " [ 46  93  93]]\n",
      "Epoch: 86, loss: 28.960, training accuracy: 57.31%\n",
      "Epoch: 86, loss: 30.263, validation accuracy: 50.82%\n",
      "[[ 99  89  50]\n",
      " [430 908 399]\n",
      " [ 36  82 115]]\n",
      "Epoch: 87, loss: 28.904, training accuracy: 57.63%\n",
      "Epoch: 87, loss: 29.602, validation accuracy: 52.90%\n",
      "[[103  94  41]\n",
      " [395 963 380]\n",
      " [ 41  89 102]]\n",
      "Epoch: 88, loss: 28.845, training accuracy: 57.78%\n",
      "Epoch: 88, loss: 29.155, validation accuracy: 54.94%\n",
      "[[ 100  101   37]\n",
      " [ 397 1012  328]\n",
      " [  45   87  101]]\n",
      "Epoch: 89, loss: 28.978, training accuracy: 57.53%\n",
      "Epoch: 89, loss: 30.141, validation accuracy: 51.99%\n",
      "[[108  84  46]\n",
      " [447 934 356]\n",
      " [ 37  90 106]]\n",
      "Epoch: 90, loss: 28.978, training accuracy: 57.55%\n",
      "Epoch: 90, loss: 29.955, validation accuracy: 52.13%\n",
      "[[114  84  41]\n",
      " [431 927 379]\n",
      " [ 40  82 110]]\n",
      "Epoch: 91, loss: 29.015, training accuracy: 57.66%\n",
      "Epoch: 91, loss: 30.220, validation accuracy: 51.13%\n",
      "[[102  82  55]\n",
      " [390 910 436]\n",
      " [ 39  77 117]]\n",
      "Epoch: 92, loss: 28.965, training accuracy: 57.60%\n",
      "Epoch: 92, loss: 29.838, validation accuracy: 52.81%\n",
      "[[103  91  45]\n",
      " [433 953 350]\n",
      " [ 50  73 110]]\n",
      "Epoch: 93, loss: 29.162, training accuracy: 57.05%\n",
      "Epoch: 93, loss: 28.531, validation accuracy: 55.62%\n",
      "[[  91  100   47]\n",
      " [ 353 1030  354]\n",
      " [  34   92  107]]\n",
      "Epoch: 94, loss: 29.174, training accuracy: 57.44%\n",
      "Epoch: 94, loss: 29.214, validation accuracy: 53.89%\n",
      "[[101  97  40]\n",
      " [398 988 351]\n",
      " [ 48  84 101]]\n",
      "Epoch: 95, loss: 29.307, training accuracy: 56.97%\n",
      "Epoch: 95, loss: 29.371, validation accuracy: 55.84%\n",
      "[[ 104   90   45]\n",
      " [ 384 1019  334]\n",
      " [  38   84  110]]\n",
      "Epoch: 96, loss: 29.367, training accuracy: 56.37%\n",
      "Epoch: 96, loss: 29.835, validation accuracy: 52.72%\n",
      "[[116  86  37]\n",
      " [448 941 347]\n",
      " [ 49  77 107]]\n",
      "Epoch: 97, loss: 29.230, training accuracy: 56.71%\n",
      "Epoch: 97, loss: 29.757, validation accuracy: 53.53%\n",
      "[[110  90  39]\n",
      " [431 974 332]\n",
      " [ 48  86  98]]\n",
      "Epoch: 98, loss: 29.229, training accuracy: 56.55%\n",
      "Epoch: 98, loss: 29.741, validation accuracy: 53.17%\n",
      "[[114  83  42]\n",
      " [424 947 365]\n",
      " [ 40  80 113]]\n",
      "Epoch: 99, loss: 29.319, training accuracy: 56.64%\n",
      "Epoch: 99, loss: 29.821, validation accuracy: 52.85%\n",
      "[[ 92  94  52]\n",
      " [420 973 345]\n",
      " [ 48  82 102]]\n"
     ]
    }
   ],
   "source": [
    "# run the training\n",
    "\n",
    "epochs = 100\n",
    "training_rounds = int(X_train_upsampled.shape[0] / batch_size)\n",
    "validation_rounds = int(X_valid.shape[0] / batch_size)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # training\n",
    "        \n",
    "        sess.run(training_init_op)\n",
    "        accumulated_acc = 0\n",
    "        accumulated_loss = 0\n",
    "        for j in range(training_rounds):\n",
    "            l, _, acc = sess.run([loss, optimizer, accuracy], feed_dict={prob: global_dropout})\n",
    "            accumulated_loss += l                                                             \n",
    "            accumulated_acc += acc\n",
    "        print(\"Epoch: {}, loss: {:.3f}, training accuracy: {:.2f}%\".format(i, accumulated_loss / training_rounds, accumulated_acc / training_rounds * 100))\n",
    "\n",
    "        # validation\n",
    "        \n",
    "        sess.run(validation_init_op)\n",
    "        accumulated_acc = 0\n",
    "        accumulated_loss = 0\n",
    "        labels = np.array([])\n",
    "        predictions = np.array([])\n",
    "        for j in range(validation_rounds):\n",
    "            l, label_, prediction_, acc = sess.run([loss, label, prediction, accuracy], feed_dict={prob: 1.0})\n",
    "            accumulated_loss += l\n",
    "            accumulated_acc += acc\n",
    "            labels = np.concatenate((labels, label_))\n",
    "            predictions = np.concatenate((predictions, prediction_))\n",
    "        print(\"Epoch: {}, loss: {:.3f}, validation accuracy: {:.2f}%\".format(i, accumulated_loss / validation_rounds, accumulated_acc / validation_rounds * 100))\n",
    "        conf = confusion_matrix(labels, predictions)\n",
    "        print(conf)\n",
    "#         plt.imshow(conf, cmap='binary', interpolation='None')\n",
    "#         plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
