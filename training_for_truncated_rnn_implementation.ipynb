{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset compute graph\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17694, 10, 53)\n",
      "(17694, 10, 3)\n",
      "(2212, 10, 53)\n",
      "(2212, 10, 3)\n",
      "(2212, 10, 53)\n",
      "(2212, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data_for_truncated_rnn.bin'\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    X_train = np.load(f).astype(np.float32)\n",
    "    y_train_onehot = np.load(f).astype(np.float32)\n",
    "    X_valid = np.load(f).astype(np.float32)\n",
    "    y_valid_onehot = np.load(f).astype(np.float32)\n",
    "    X_test = np.load(f).astype(np.float32)\n",
    "    y_test_onehot = np.load(f).astype(np.float32)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_train_onehot.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid_onehot.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## neural network parameters and architecture\n",
    "\n",
    "# network parameters\n",
    "\n",
    "batch_size = 1\n",
    "input_dim = 53\n",
    "output_dim = 3\n",
    "num_steps = 10\n",
    "state_size = 100\n",
    "num_layers = 3\n",
    "learning_rate = 1e-4\n",
    "global_dropout = .8\n",
    "\n",
    "# feed_dict placeholders\n",
    "\n",
    "X = tf.placeholder(tf.float32, [batch_size, num_steps, input_dim], name='X')\n",
    "y = tf.placeholder(tf.float32, [batch_size, num_steps, output_dim], name='y')\n",
    "keep_prob = tf.placeholder_with_default(1.0, shape=(), name='keep_prob')\n",
    "\n",
    "# forward pass\n",
    "\n",
    "input_series = tf.unstack(X, axis=1)\n",
    "label_series = tf.unstack(y, axis=1)\n",
    "\n",
    "def rnn_cell_with_dropout():\n",
    "    return tf.nn.rnn_cell.DropoutWrapper(\n",
    "        tf.nn.rnn_cell.BasicRNNCell(num_units=state_size), \n",
    "        input_keep_prob=keep_prob)\n",
    "\n",
    "cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "    tf.nn.rnn_cell.MultiRNNCell([rnn_cell_with_dropout() for _ in range(num_layers)]),\n",
    "    output_keep_prob=keep_prob)\n",
    "\n",
    "output_series = []\n",
    "state_series = []\n",
    "initial_state = state = cell.zero_state(batch_size, tf.float32)\n",
    "for current_input in input_series:\n",
    "    output, state = cell(current_input, state)\n",
    "    output_series.append(output)\n",
    "    state_series.append(state)\n",
    "first_state = state_series[0]\n",
    "    \n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, output_dim])\n",
    "    b = tf.get_variable('b', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "logits_series = [tf.matmul(output, W) + b for output in output_series]\n",
    "\n",
    "# backward propagation\n",
    "\n",
    "losses = [tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits) for logits, labels in zip(logits_series,label_series)]\n",
    "\n",
    "# adjust for label imbalance and time\n",
    "c = tf.constant([[7.143], [1.389], [7.143]])\n",
    "# c = tf.constant([[7.143], [0.6945], [7.143]])\n",
    "weight_series = []\n",
    "for i in range(num_steps):\n",
    "    weight_series.append((i+1)*0.1*tf.matmul(label_series[i], c))\n",
    "losses = [tf.multiply(losses, weights) for losses, weights in zip(losses, weight_series)]\n",
    "\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "# calculate accuracy\n",
    "\n",
    "last_label = label_series[num_steps-1]\n",
    "last_prediction = tf.nn.softmax(logits_series[num_steps-1])\n",
    "\n",
    "label = tf.argmax(last_label, 1)\n",
    "prediction = tf.argmax(last_prediction, 1)\n",
    "\n",
    "equality = tf.equal(prediction, label)\n",
    "accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.698, training accuracy: 45.27%\n",
      "Epoch: 0, loss: 1.435, validation accuracy: 55.92%\n",
      "[[ 129   97   13]\n",
      " [ 560 1045  135]\n",
      " [  35  135   63]]\n",
      "Epoch: 1, loss: 1.647, training accuracy: 47.51%\n",
      "Epoch: 1, loss: 1.420, validation accuracy: 57.73%\n",
      "[[ 121  102   16]\n",
      " [ 495 1078  167]\n",
      " [  29  126   78]]\n",
      "Epoch: 2, loss: 1.635, training accuracy: 47.43%\n",
      "Epoch: 2, loss: 1.421, validation accuracy: 63.92%\n",
      "[[  97  126   16]\n",
      " [ 348 1250  142]\n",
      " [  24  142   67]]\n",
      "Epoch: 3, loss: 1.632, training accuracy: 47.20%\n",
      "Epoch: 3, loss: 1.437, validation accuracy: 63.34%\n",
      "[[  92  129   18]\n",
      " [ 349 1242  149]\n",
      " [  27  139   67]]\n",
      "Epoch: 4, loss: 1.627, training accuracy: 47.69%\n",
      "Epoch: 4, loss: 1.439, validation accuracy: 64.29%\n",
      "[[  78  136   25]\n",
      " [ 307 1267  166]\n",
      " [  23  133   77]]\n",
      "Epoch: 5, loss: 1.623, training accuracy: 48.00%\n",
      "Epoch: 5, loss: 1.413, validation accuracy: 66.64%\n",
      "[[  71  146   22]\n",
      " [ 251 1323  166]\n",
      " [  24  129   80]]\n",
      "Epoch: 6, loss: 1.621, training accuracy: 48.29%\n",
      "Epoch: 6, loss: 1.402, validation accuracy: 66.32%\n",
      "[[  74  137   28]\n",
      " [ 266 1311  163]\n",
      " [  21  130   82]]\n",
      "Epoch: 7, loss: 1.617, training accuracy: 48.72%\n",
      "Epoch: 7, loss: 1.410, validation accuracy: 70.12%\n",
      "[[  71  147   21]\n",
      " [ 191 1402  147]\n",
      " [  20  135   78]]\n",
      "Epoch: 8, loss: 1.610, training accuracy: 48.93%\n",
      "Epoch: 8, loss: 1.419, validation accuracy: 69.62%\n",
      "[[  64  151   24]\n",
      " [ 189 1397  154]\n",
      " [  20  134   79]]\n",
      "Epoch: 9, loss: 1.606, training accuracy: 49.66%\n",
      "Epoch: 9, loss: 1.419, validation accuracy: 70.57%\n",
      "[[  57  158   24]\n",
      " [ 155 1424  161]\n",
      " [  17  136   80]]\n",
      "Epoch: 10, loss: 1.603, training accuracy: 49.55%\n",
      "Epoch: 10, loss: 1.412, validation accuracy: 69.98%\n",
      "[[  63  151   25]\n",
      " [ 180 1405  155]\n",
      " [  21  132   80]]\n",
      "Epoch: 11, loss: 1.596, training accuracy: 49.16%\n",
      "Epoch: 11, loss: 1.415, validation accuracy: 67.36%\n",
      "[[  75  137   27]\n",
      " [ 241 1335  164]\n",
      " [  21  132   80]]\n",
      "Epoch: 12, loss: 1.595, training accuracy: 49.47%\n",
      "Epoch: 12, loss: 1.408, validation accuracy: 66.86%\n",
      "[[  76  140   23]\n",
      " [ 238 1320  182]\n",
      " [  22  128   83]]\n",
      "Epoch: 13, loss: 1.589, training accuracy: 49.93%\n",
      "Epoch: 13, loss: 1.412, validation accuracy: 68.67%\n",
      "[[  69  149   21]\n",
      " [ 212 1370  158]\n",
      " [  20  133   80]]\n",
      "Epoch: 14, loss: 1.583, training accuracy: 49.95%\n",
      "Epoch: 14, loss: 1.426, validation accuracy: 69.03%\n",
      "[[  73  144   22]\n",
      " [ 208 1371  161]\n",
      " [  18  132   83]]\n",
      "Epoch: 15, loss: 1.579, training accuracy: 49.82%\n",
      "Epoch: 15, loss: 1.433, validation accuracy: 68.85%\n",
      "[[  69  149   21]\n",
      " [ 210 1375  155]\n",
      " [  18  136   79]]\n",
      "Epoch: 16, loss: 1.573, training accuracy: 50.37%\n",
      "Epoch: 16, loss: 1.432, validation accuracy: 69.30%\n",
      "[[  65  149   25]\n",
      " [ 184 1389  167]\n",
      " [  17  137   79]]\n",
      "Epoch: 17, loss: 1.570, training accuracy: 50.84%\n",
      "Epoch: 17, loss: 1.414, validation accuracy: 68.17%\n",
      "[[  73  139   27]\n",
      " [ 206 1348  186]\n",
      " [  21  125   87]]\n",
      "Epoch: 18, loss: 1.563, training accuracy: 49.97%\n",
      "Epoch: 18, loss: 1.437, validation accuracy: 69.30%\n",
      "[[  64  151   24]\n",
      " [ 174 1389  177]\n",
      " [  20  133   80]]\n",
      "Epoch: 19, loss: 1.559, training accuracy: 51.29%\n",
      "Epoch: 19, loss: 1.439, validation accuracy: 68.76%\n",
      "[[  70  144   25]\n",
      " [ 192 1371  177]\n",
      " [  20  133   80]]\n",
      "Epoch: 20, loss: 1.553, training accuracy: 50.66%\n",
      "Epoch: 20, loss: 1.433, validation accuracy: 66.55%\n",
      "[[  69  141   29]\n",
      " [ 205 1314  221]\n",
      " [  20  124   89]]\n",
      "Epoch: 21, loss: 1.547, training accuracy: 51.19%\n",
      "Epoch: 21, loss: 1.456, validation accuracy: 68.99%\n",
      "[[  60  156   23]\n",
      " [ 189 1382  169]\n",
      " [  18  131   84]]\n",
      "Epoch: 22, loss: 1.542, training accuracy: 51.16%\n",
      "Epoch: 22, loss: 1.465, validation accuracy: 68.26%\n",
      "[[  57  149   33]\n",
      " [ 190 1369  181]\n",
      " [  19  130   84]]\n",
      "Epoch: 23, loss: 1.534, training accuracy: 51.51%\n",
      "Epoch: 23, loss: 1.468, validation accuracy: 67.95%\n",
      "[[  52  157   30]\n",
      " [ 179 1361  200]\n",
      " [  18  125   90]]\n",
      "Epoch: 24, loss: 1.526, training accuracy: 51.13%\n",
      "Epoch: 24, loss: 1.494, validation accuracy: 68.44%\n",
      "[[  67  146   26]\n",
      " [ 186 1361  193]\n",
      " [  19  128   86]]\n",
      "Epoch: 25, loss: 1.526, training accuracy: 51.20%\n",
      "Epoch: 25, loss: 1.491, validation accuracy: 66.68%\n",
      "[[  58  154   27]\n",
      " [ 201 1331  208]\n",
      " [  20  127   86]]\n",
      "Epoch: 26, loss: 1.517, training accuracy: 51.68%\n",
      "Epoch: 26, loss: 1.486, validation accuracy: 68.13%\n",
      "[[  60  150   29]\n",
      " [ 198 1362  180]\n",
      " [  18  130   85]]\n",
      "Epoch: 27, loss: 1.515, training accuracy: 51.50%\n",
      "Epoch: 27, loss: 1.499, validation accuracy: 67.86%\n",
      "[[  61  157   21]\n",
      " [ 197 1356  187]\n",
      " [  16  133   84]]\n",
      "Epoch: 28, loss: 1.502, training accuracy: 51.06%\n",
      "Epoch: 28, loss: 1.500, validation accuracy: 67.45%\n",
      "[[  60  150   29]\n",
      " [ 188 1345  207]\n",
      " [  23  123   87]]\n",
      "Epoch: 29, loss: 1.498, training accuracy: 51.10%\n",
      "Epoch: 29, loss: 1.533, validation accuracy: 67.50%\n",
      "[[  56  156   27]\n",
      " [ 193 1356  191]\n",
      " [  19  133   81]]\n",
      "Epoch: 30, loss: 1.497, training accuracy: 51.96%\n",
      "Epoch: 30, loss: 1.519, validation accuracy: 66.68%\n",
      "[[  62  147   30]\n",
      " [ 206 1333  201]\n",
      " [  23  130   80]]\n",
      "Epoch: 31, loss: 1.477, training accuracy: 51.75%\n",
      "Epoch: 31, loss: 1.522, validation accuracy: 68.08%\n",
      "[[  59  155   25]\n",
      " [ 190 1362  188]\n",
      " [  21  127   85]]\n",
      "Epoch: 32, loss: 1.481, training accuracy: 51.63%\n",
      "Epoch: 32, loss: 1.522, validation accuracy: 66.64%\n",
      "[[  69  144   26]\n",
      " [ 223 1324  193]\n",
      " [  24  128   81]]\n",
      "Epoch: 33, loss: 1.479, training accuracy: 51.89%\n",
      "Epoch: 33, loss: 1.541, validation accuracy: 68.85%\n",
      "[[  63  145   31]\n",
      " [ 174 1388  178]\n",
      " [  23  138   72]]\n",
      "Epoch: 34, loss: 1.464, training accuracy: 52.34%\n",
      "Epoch: 34, loss: 1.549, validation accuracy: 66.18%\n",
      "[[  64  146   29]\n",
      " [ 218 1318  204]\n",
      " [  17  134   82]]\n",
      "Epoch: 35, loss: 1.466, training accuracy: 52.26%\n",
      "Epoch: 35, loss: 1.568, validation accuracy: 66.05%\n",
      "[[  61  147   31]\n",
      " [ 217 1316  207]\n",
      " [  21  128   84]]\n",
      "Epoch: 36, loss: 1.454, training accuracy: 52.53%\n",
      "Epoch: 36, loss: 1.567, validation accuracy: 65.91%\n",
      "[[  63  150   26]\n",
      " [ 217 1317  206]\n",
      " [  22  133   78]]\n",
      "Epoch: 37, loss: 1.459, training accuracy: 52.64%\n",
      "Epoch: 37, loss: 1.571, validation accuracy: 67.50%\n",
      "[[  59  150   30]\n",
      " [ 187 1360  193]\n",
      " [  20  139   74]]\n",
      "Epoch: 38, loss: 1.446, training accuracy: 52.48%\n",
      "Epoch: 38, loss: 1.583, validation accuracy: 67.45%\n",
      "[[  63  151   25]\n",
      " [ 211 1359  170]\n",
      " [  18  145   70]]\n",
      "Epoch: 39, loss: 1.446, training accuracy: 52.68%\n",
      "Epoch: 39, loss: 1.597, validation accuracy: 67.04%\n",
      "[[  71  140   28]\n",
      " [ 214 1340  186]\n",
      " [  19  142   72]]\n",
      "Epoch: 40, loss: 1.440, training accuracy: 52.95%\n",
      "Epoch: 40, loss: 1.635, validation accuracy: 67.22%\n",
      "[[  56  146   37]\n",
      " [ 200 1354  186]\n",
      " [  16  140   77]]\n",
      "Epoch: 41, loss: 1.428, training accuracy: 53.19%\n",
      "Epoch: 41, loss: 1.606, validation accuracy: 65.24%\n",
      "[[  56  153   30]\n",
      " [ 219 1310  211]\n",
      " [  22  134   77]]\n",
      "Epoch: 42, loss: 1.435, training accuracy: 53.02%\n",
      "Epoch: 42, loss: 1.623, validation accuracy: 66.32%\n",
      "[[  57  152   30]\n",
      " [ 215 1338  187]\n",
      " [  24  137   72]]\n",
      "Epoch: 43, loss: 1.433, training accuracy: 53.14%\n",
      "Epoch: 43, loss: 1.613, validation accuracy: 66.55%\n",
      "[[  54  152   33]\n",
      " [ 207 1343  190]\n",
      " [  18  140   75]]\n",
      "Epoch: 44, loss: 1.417, training accuracy: 52.82%\n",
      "Epoch: 44, loss: 1.631, validation accuracy: 65.33%\n",
      "[[  68  142   29]\n",
      " [ 247 1306  187]\n",
      " [  20  142   71]]\n",
      "Epoch: 45, loss: 1.412, training accuracy: 53.32%\n",
      "Epoch: 45, loss: 1.659, validation accuracy: 67.59%\n",
      "[[  49  162   28]\n",
      " [ 202 1381  157]\n",
      " [  20  148   65]]\n",
      "Epoch: 46, loss: 1.411, training accuracy: 53.65%\n",
      "Epoch: 46, loss: 1.643, validation accuracy: 67.77%\n",
      "[[  65  145   29]\n",
      " [ 199 1365  176]\n",
      " [  15  149   69]]\n",
      "Epoch: 47, loss: 1.413, training accuracy: 53.44%\n",
      "Epoch: 47, loss: 1.635, validation accuracy: 66.55%\n",
      "[[  64  143   32]\n",
      " [ 211 1336  193]\n",
      " [  16  145   72]]\n",
      "Epoch: 48, loss: 1.408, training accuracy: 53.07%\n",
      "Epoch: 48, loss: 1.660, validation accuracy: 68.08%\n",
      "[[  56  156   27]\n",
      " [ 191 1388  161]\n",
      " [  19  152   62]]\n",
      "Epoch: 49, loss: 1.408, training accuracy: 53.40%\n",
      "Epoch: 49, loss: 1.637, validation accuracy: 65.28%\n",
      "[[  60  146   33]\n",
      " [ 237 1301  202]\n",
      " [  20  130   83]]\n",
      "Epoch: 50, loss: 1.394, training accuracy: 53.67%\n",
      "Epoch: 50, loss: 1.687, validation accuracy: 66.77%\n",
      "[[  59  151   29]\n",
      " [ 223 1351  166]\n",
      " [  18  148   67]]\n",
      "Epoch: 51, loss: 1.393, training accuracy: 53.41%\n",
      "Epoch: 51, loss: 1.684, validation accuracy: 65.87%\n",
      "[[  63  144   32]\n",
      " [ 238 1324  178]\n",
      " [  21  142   70]]\n",
      "Epoch: 52, loss: 1.378, training accuracy: 54.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, loss: 1.691, validation accuracy: 66.27%\n",
      "[[  59  148   32]\n",
      " [ 229 1337  174]\n",
      " [  24  139   70]]\n",
      "Epoch: 53, loss: 1.387, training accuracy: 54.24%\n",
      "Epoch: 53, loss: 1.691, validation accuracy: 66.05%\n",
      "[[  52  149   38]\n",
      " [ 217 1335  188]\n",
      " [  19  140   74]]\n",
      "Epoch: 54, loss: 1.383, training accuracy: 53.74%\n",
      "Epoch: 54, loss: 1.696, validation accuracy: 65.10%\n",
      "[[  57  144   38]\n",
      " [ 224 1313  203]\n",
      " [  21  142   70]]\n",
      "Epoch: 55, loss: 1.384, training accuracy: 54.00%\n",
      "Epoch: 55, loss: 1.713, validation accuracy: 66.59%\n",
      "[[  61  146   32]\n",
      " [ 226 1341  173]\n",
      " [  16  146   71]]\n",
      "Epoch: 56, loss: 1.376, training accuracy: 53.50%\n",
      "Epoch: 56, loss: 1.696, validation accuracy: 66.64%\n",
      "[[  67  146   26]\n",
      " [ 227 1342  171]\n",
      " [  25  143   65]]\n",
      "Epoch: 57, loss: 1.370, training accuracy: 54.13%\n",
      "Epoch: 57, loss: 1.722, validation accuracy: 66.09%\n",
      "[[  63  146   30]\n",
      " [ 240 1330  170]\n",
      " [  23  141   69]]\n",
      "Epoch: 58, loss: 1.361, training accuracy: 54.73%\n",
      "Epoch: 58, loss: 1.755, validation accuracy: 66.27%\n",
      "[[  63  147   29]\n",
      " [ 230 1333  177]\n",
      " [  24  139   70]]\n",
      "Epoch: 59, loss: 1.356, training accuracy: 54.32%\n",
      "Epoch: 59, loss: 1.709, validation accuracy: 66.64%\n",
      "[[  64  147   28]\n",
      " [ 223 1340  177]\n",
      " [  25  138   70]]\n",
      "Epoch: 60, loss: 1.362, training accuracy: 54.05%\n",
      "Epoch: 60, loss: 1.707, validation accuracy: 65.24%\n",
      "[[  64  144   31]\n",
      " [ 265 1312  163]\n",
      " [  24  142   67]]\n",
      "Epoch: 61, loss: 1.351, training accuracy: 54.65%\n",
      "Epoch: 61, loss: 1.749, validation accuracy: 65.55%\n",
      "[[  53  154   32]\n",
      " [ 249 1328  163]\n",
      " [  20  144   69]]\n",
      "Epoch: 62, loss: 1.360, training accuracy: 54.77%\n",
      "Epoch: 62, loss: 1.713, validation accuracy: 66.23%\n",
      "[[  59  153   27]\n",
      " [ 230 1336  174]\n",
      " [  24  139   70]]\n",
      "Epoch: 63, loss: 1.347, training accuracy: 54.64%\n",
      "Epoch: 63, loss: 1.723, validation accuracy: 65.69%\n",
      "[[  64  140   35]\n",
      " [ 237 1321  182]\n",
      " [  18  147   68]]\n",
      "Epoch: 64, loss: 1.347, training accuracy: 55.13%\n",
      "Epoch: 64, loss: 1.731, validation accuracy: 65.51%\n",
      "[[  58  150   31]\n",
      " [ 224 1324  192]\n",
      " [  19  147   67]]\n",
      "Epoch: 65, loss: 1.341, training accuracy: 55.14%\n",
      "Epoch: 65, loss: 1.764, validation accuracy: 66.41%\n",
      "[[  63  148   28]\n",
      " [ 229 1336  175]\n",
      " [  16  147   70]]\n",
      "Epoch: 66, loss: 1.343, training accuracy: 54.82%\n",
      "Epoch: 66, loss: 1.737, validation accuracy: 66.91%\n",
      "[[  52  159   28]\n",
      " [ 213 1362  165]\n",
      " [  17  150   66]]\n",
      "Epoch: 67, loss: 1.333, training accuracy: 55.24%\n",
      "Epoch: 67, loss: 1.734, validation accuracy: 65.51%\n",
      "[[  59  152   28]\n",
      " [ 257 1325  158]\n",
      " [  18  150   65]]\n",
      "Epoch: 68, loss: 1.335, training accuracy: 55.30%\n",
      "Epoch: 68, loss: 1.762, validation accuracy: 66.46%\n",
      "[[  59  151   29]\n",
      " [ 235 1345  160]\n",
      " [  20  147   66]]\n",
      "Epoch: 69, loss: 1.339, training accuracy: 54.95%\n",
      "Epoch: 69, loss: 1.732, validation accuracy: 66.91%\n",
      "[[  50  156   33]\n",
      " [ 213 1360  167]\n",
      " [  16  147   70]]\n",
      "Epoch: 70, loss: 1.325, training accuracy: 55.41%\n",
      "Epoch: 70, loss: 1.764, validation accuracy: 65.33%\n",
      "[[  64  142   33]\n",
      " [ 240 1312  188]\n",
      " [  23  141   69]]\n",
      "Epoch: 71, loss: 1.330, training accuracy: 55.31%\n",
      "Epoch: 71, loss: 1.757, validation accuracy: 65.69%\n",
      "[[  59  148   32]\n",
      " [ 262 1315  163]\n",
      " [  22  132   79]]\n",
      "Epoch: 72, loss: 1.326, training accuracy: 55.52%\n",
      "Epoch: 72, loss: 1.787, validation accuracy: 66.82%\n",
      "[[  58  151   30]\n",
      " [ 238 1348  154]\n",
      " [  19  142   72]]\n",
      "Epoch: 73, loss: 1.322, training accuracy: 55.20%\n",
      "Epoch: 73, loss: 1.776, validation accuracy: 65.46%\n",
      "[[  57  150   32]\n",
      " [ 249 1323  168]\n",
      " [  20  145   68]]\n",
      "Epoch: 74, loss: 1.317, training accuracy: 55.60%\n",
      "Epoch: 74, loss: 1.763, validation accuracy: 64.83%\n",
      "[[  56  148   35]\n",
      " [ 245 1305  190]\n",
      " [  17  143   73]]\n",
      "Epoch: 75, loss: 1.318, training accuracy: 55.37%\n",
      "Epoch: 75, loss: 1.799, validation accuracy: 66.00%\n",
      "[[  53  159   27]\n",
      " [ 218 1340  182]\n",
      " [  19  147   67]]\n",
      "Epoch: 76, loss: 1.309, training accuracy: 55.12%\n",
      "Epoch: 76, loss: 1.778, validation accuracy: 65.55%\n",
      "[[  58  151   30]\n",
      " [ 245 1322  173]\n",
      " [  20  143   70]]\n",
      "Epoch: 77, loss: 1.308, training accuracy: 55.71%\n",
      "Epoch: 77, loss: 1.771, validation accuracy: 65.60%\n",
      "[[  58  147   34]\n",
      " [ 244 1315  181]\n",
      " [  20  135   78]]\n",
      "Epoch: 78, loss: 1.308, training accuracy: 55.88%\n",
      "Epoch: 78, loss: 1.758, validation accuracy: 66.09%\n",
      "[[  58  152   29]\n",
      " [ 233 1332  175]\n",
      " [  20  141   72]]\n",
      "Epoch: 79, loss: 1.304, training accuracy: 55.15%\n",
      "Epoch: 79, loss: 1.767, validation accuracy: 66.14%\n",
      "[[  67  147   25]\n",
      " [ 250 1325  165]\n",
      " [  24  138   71]]\n",
      "Epoch: 80, loss: 1.317, training accuracy: 55.27%\n",
      "Epoch: 80, loss: 1.797, validation accuracy: 66.59%\n",
      "[[  51  152   36]\n",
      " [ 212 1349  179]\n",
      " [  21  139   73]]\n",
      "Epoch: 81, loss: 1.307, training accuracy: 55.74%\n",
      "Epoch: 81, loss: 1.756, validation accuracy: 66.41%\n",
      "[[  57  149   33]\n",
      " [ 228 1339  173]\n",
      " [  20  140   73]]\n",
      "Epoch: 82, loss: 1.314, training accuracy: 55.54%\n",
      "Epoch: 82, loss: 1.818, validation accuracy: 65.28%\n",
      "[[  64  145   30]\n",
      " [ 244 1312  184]\n",
      " [  25  140   68]]\n",
      "Epoch: 83, loss: 1.296, training accuracy: 56.26%\n",
      "Epoch: 83, loss: 1.776, validation accuracy: 65.82%\n",
      "[[  62  148   29]\n",
      " [ 246 1320  174]\n",
      " [  20  139   74]]\n",
      "Epoch: 84, loss: 1.302, training accuracy: 56.21%\n",
      "Epoch: 84, loss: 1.749, validation accuracy: 67.31%\n",
      "[[  57  153   29]\n",
      " [ 216 1364  160]\n",
      " [  23  142   68]]\n",
      "Epoch: 85, loss: 1.291, training accuracy: 55.96%\n",
      "Epoch: 85, loss: 1.802, validation accuracy: 67.09%\n",
      "[[  66  146   27]\n",
      " [ 222 1353  165]\n",
      " [  19  149   65]]\n",
      "Epoch: 86, loss: 1.283, training accuracy: 55.94%\n",
      "Epoch: 86, loss: 1.808, validation accuracy: 66.46%\n",
      "[[  63  141   35]\n",
      " [ 239 1332  169]\n",
      " [  21  137   75]]\n",
      "Epoch: 87, loss: 1.285, training accuracy: 56.30%\n",
      "Epoch: 87, loss: 1.784, validation accuracy: 65.55%\n",
      "[[  51  161   27]\n",
      " [ 239 1333  168]\n",
      " [  21  146   66]]\n",
      "Epoch: 88, loss: 1.291, training accuracy: 55.84%\n",
      "Epoch: 88, loss: 1.817, validation accuracy: 66.50%\n",
      "[[  48  164   27]\n",
      " [ 230 1359  151]\n",
      " [  19  150   64]]\n",
      "Epoch: 89, loss: 1.290, training accuracy: 56.38%\n",
      "Epoch: 89, loss: 1.822, validation accuracy: 65.78%\n",
      "[[  64  143   32]\n",
      " [ 234 1326  180]\n",
      " [  24  144   65]]\n",
      "Epoch: 90, loss: 1.286, training accuracy: 56.27%\n",
      "Epoch: 90, loss: 1.812, validation accuracy: 66.73%\n",
      "[[  59  152   28]\n",
      " [ 227 1344  169]\n",
      " [  23  137   73]]\n",
      "Epoch: 91, loss: 1.278, training accuracy: 56.78%\n",
      "Epoch: 91, loss: 1.811, validation accuracy: 67.86%\n",
      "[[  51  156   32]\n",
      " [ 197 1377  166]\n",
      " [  16  144   73]]\n",
      "Epoch: 92, loss: 1.277, training accuracy: 56.75%\n",
      "Epoch: 92, loss: 1.774, validation accuracy: 65.69%\n",
      "[[  53  152   34]\n",
      " [ 233 1326  181]\n",
      " [  15  144   74]]\n",
      "Epoch: 93, loss: 1.284, training accuracy: 56.24%\n",
      "Epoch: 93, loss: 1.817, validation accuracy: 65.78%\n",
      "[[  60  148   31]\n",
      " [ 231 1321  188]\n",
      " [  21  138   74]]\n",
      "Epoch: 94, loss: 1.290, training accuracy: 56.01%\n",
      "Epoch: 94, loss: 1.843, validation accuracy: 65.42%\n",
      "[[  59  142   38]\n",
      " [ 246 1322  172]\n",
      " [  25  142   66]]\n",
      "Epoch: 95, loss: 1.273, training accuracy: 56.46%\n",
      "Epoch: 95, loss: 1.814, validation accuracy: 65.42%\n",
      "[[  57  151   31]\n",
      " [ 259 1323  158]\n",
      " [  20  146   67]]\n",
      "Epoch: 96, loss: 1.270, training accuracy: 56.12%\n",
      "Epoch: 96, loss: 1.843, validation accuracy: 67.13%\n",
      "[[  60  150   29]\n",
      " [ 228 1352  160]\n",
      " [  20  140   73]]\n",
      "Epoch: 97, loss: 1.269, training accuracy: 56.69%\n",
      "Epoch: 97, loss: 1.858, validation accuracy: 68.08%\n",
      "[[  45  160   34]\n",
      " [ 198 1393  149]\n",
      " [  15  150   68]]\n",
      "Epoch: 98, loss: 1.277, training accuracy: 56.35%\n",
      "Epoch: 98, loss: 1.860, validation accuracy: 64.33%\n",
      "[[  51  167   21]\n",
      " [ 267 1303  170]\n",
      " [  23  141   69]]\n",
      "Epoch: 99, loss: 1.274, training accuracy: 56.58%\n",
      "Epoch: 99, loss: 1.893, validation accuracy: 65.42%\n",
      "[[  51  152   36]\n",
      " [ 233 1331  176]\n",
      " [  19  149   65]]\n"
     ]
    }
   ],
   "source": [
    "# run the training\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # training\n",
    "        \n",
    "        numpy_state = sess.run(initial_state)\n",
    "    \n",
    "        accumulated_acc = 0\n",
    "        accumulated_loss = 0\n",
    "        training_iterations = X_train.shape[0]\n",
    "        for j in range(training_iterations):\n",
    "            _, l, numpy_state, acc = sess.run([train_step, total_loss, first_state, accuracy], feed_dict={X:X_train[j:j+1], y:y_train_onehot[j:j+1], initial_state: numpy_state, keep_prob: global_dropout})\n",
    "            accumulated_loss += l\n",
    "            accumulated_acc += acc\n",
    "        print(\"Epoch: {}, loss: {:.3f}, training accuracy: {:.2f}%\".format(i, accumulated_loss / training_iterations, accumulated_acc / training_iterations * 100))\n",
    "        \n",
    "        # validation\n",
    "        \n",
    "        numpy_state = sess.run(initial_state)\n",
    "        \n",
    "        accumulated_acc = 0\n",
    "        accumulated_loss = 0\n",
    "        labels = np.array([])\n",
    "        predictions = np.array([])\n",
    "        validation_iterations = X_valid.shape[0]\n",
    "        for j in range(validation_iterations):\n",
    "            l, numpy_state, acc, label_, prediction_ = sess.run([total_loss, first_state, accuracy, label, prediction], feed_dict={X:X_valid[j:j+1], y:y_valid_onehot[j:j+1], initial_state: numpy_state, keep_prob: 1.0})\n",
    "            accumulated_loss += l\n",
    "            accumulated_acc += acc\n",
    "            labels = np.concatenate((labels, label_))\n",
    "            predictions = np.concatenate((predictions, prediction_))\n",
    "        print(\"Epoch: {}, loss: {:.3f}, validation accuracy: {:.2f}%\".format(i, accumulated_loss / validation_iterations, accumulated_acc / validation_iterations * 100))\n",
    "        conf = confusion_matrix(labels, predictions)\n",
    "        print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
